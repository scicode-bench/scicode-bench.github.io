# Leaderboard

<center>

# SciCode Leaderboard

| Models                   | Main Problem Resolve Rate           | <span style="color:grey">Subproblem</span>            |
|--------------------------|-------------------------------------|-------------------------------------|
| ðŸ¥‡ OpenAI o3-mini-low    | <div align="center">**10.8**</div>      | <div align="center" style="color:grey">33.3</div>     |
| ðŸ¥ˆ OpenAI o3-mini-high   | <div align="center">**9.2**</div>       | <div align="center" style="color:grey">34.4</div>     |
| ðŸ¥‰ OpenAI o3-mini-medium | <div align="center">**9.2**</div>       | <div align="center" style="color:grey">33.0</div>     |
| OpenAI o1-preview        | <div align="center">**7.7**</div>       | <div align="center" style="color:grey">28.5</div>     |
| Deepseek-R1              | <div align="center">**4.6**</div>       | <div align="center" style="color:grey">28.5</div>     |
| Claude3.5-Sonnet         | <div align="center">**4.6**</div>       | <div align="center" style="color:grey">26.0</div>     |
| Claude3.5-Sonnet (new)   | <div align="center">**4.6**</div>       | <div align="center" style="color:grey">25.3</div>     |
| Deepseek-v3              | <div align="center">**3.1**</div>       | <div align="center" style="color:grey">23.7</div>     |
| Deepseek-Coder-v2        | <div align="center">**3.1**</div>       | <div align="center" style="color:grey">21.2</div>     |
| GPT-4o                   | <div align="center">**1.5**</div>       | <div align="center" style="color:grey">25.0</div>     |
| GPT-4-Turbo              | <div align="center">**1.5**</div>       | <div align="center" style="color:grey">22.9</div>     |
| OpenAI o1-mini           | <div align="center">**1.5**</div>       | <div align="center" style="color:grey">22.2</div>     |
| Gemini 1.5 Pro           | <div align="center">**1.5**</div>       | <div align="center" style="color:grey">21.9</div>     |
| Claude3-Opus             | <div align="center">**1.5**</div>       | <div align="center" style="color:grey">21.5</div>     |
| Llama-3.1-405B-Chat      | <div align="center">**1.5**</div>       | <div align="center" style="color:grey">19.8</div>     |
| Claude3-Sonnet           | <div align="center">**1.5**</div>       | <div align="center" style="color:grey">17.0</div>     |
| Qwen2-72B-Instruct       | <div align="center">**1.5**</div>       | <div align="center" style="color:grey">17.0</div>     |
| Llama-3.1-70B-Chat       | <div align="center">**0.0**</div>       | <div align="center" style="color:grey">17.0</div>     |
| Mixtral-8x22B-Instruct   | <div align="center">**0.0**</div>       | <div align="center" style="color:grey">16.3</div>     |
| Llama-3-70B-Chat         | <div align="center">**0.0**</div>       | <div align="center" style="color:grey">14.6</div>     |

**Note: If the models tie in the Main Problem resolve rate, we will then compare the Subproblems.**

<!-- Once you've added the results to the submission repository,
     bring back the table here -->
<!-- include-markdown "leaderboard_table.md" -->

</center>

!!! tip "How to submit"
    Want to submit your own model? Submit a request via a [Github issue](https://github.com/scicode-bench/SciCode/issues).
