# Leaderboard

<div align="center" markdown="1">

| Models                   | Main Problem Resolve Rate | <span style="color:grey">Subproblem</span> |
|--------------------------|:-------------------------:|:--------------------------------------------:|
| ðŸ¥‡ OpenAI o3-mini-low    | **10.8**                  | <span style="color:grey">33.3</span>        |
| ðŸ¥ˆ OpenAI o3-mini-high   | **9.2**                   | <span style="color:grey">34.4</span>        |
| ðŸ¥‰ OpenAI o3-mini-medium | **9.2**                   | <span style="color:grey">33.0</span>        |
| OpenAI o1-preview        | **7.7**                   | <span style="color:grey">28.5</span>        |
| Deepseek-R1              | **4.6**                   | <span style="color:grey">28.5</span>        |
| Claude3.5-Sonnet         | **4.6**                   | <span style="color:grey">26.0</span>        |
| Claude3.5-Sonnet (new)   | **4.6**                   | <span style="color:grey">25.3</span>        |
| Deepseek-v3              | **3.1**                   | <span style="color:grey">23.7</span>        |
| Deepseek-Coder-v2        | **3.1**                   | <span style="color:grey">21.2</span>        |
| GPT-4o                   | **1.5**                   | <span style="color:grey">25.0</span>        |
| GPT-4-Turbo              | **1.5**                   | <span style="color:grey">22.9</span>        |
| OpenAI o1-mini           | **1.5**                   | <span style="color:grey">22.2</span>        |
| Gemini 1.5 Pro           | **1.5**                   | <span style="color:grey">21.9</span>        |
| Claude3-Opus             | **1.5**                   | <span style="color:grey">21.5</span>        |
| Llama-3.1-405B-Chat      | **1.5**                   | <span style="color:grey">19.8</span>        |
| Claude3-Sonnet           | **1.5**                   | <span style="color:grey">17.0</span>        |
| Qwen2-72B-Instruct       | **1.5**                   | <span style="color:grey">17.0</span>        |
| Llama-3.1-70B-Chat       | **0.0**                   | <span style="color:grey">17.0</span>        |
| Mixtral-8x22B-Instruct   | **0.0**                   | <span style="color:grey">16.3</span>        |
| Llama-3-70B-Chat         | **0.0**                   | <span style="color:grey">14.6</span>        |

**Note: If the models tie in the Main Problem resolve rate, we will then compare the Subproblems.**

<!-- Once you've added the results to the submission repository,
     bring back the table here -->
<!-- include-markdown "leaderboard_table.md" -->

</div>

!!! tip "How to submit"
    Want to submit your own model? Submit a request via a [Github issue](https://github.com/scicode-bench/SciCode/issues).
